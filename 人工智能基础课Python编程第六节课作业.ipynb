{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.kaikeba.com/web/kkb_index/img_index_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础课第一部分（python）第六次作业  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，大家好!  欢迎各位开始学习我们的人工智能课程。  \n",
    "这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。  \n",
    "这门课程结束后，希望大家掌握Python语言以及人工智能基础知识，对CV，NLP，RS领域有一定深入的理解与编程能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 如何提交作业\n",
    "有关代码的作业，在上课平台上提交，具体方式，见作业提交指南\n",
    "## 2. 作业截止时间\n",
    "作业能帮助你回顾课堂内容，你又可以通过作业进行代码实操。咱们可要认真、及时的完成作业哦！自布置作业起两周内提交，助教及时批改作业哦～逾期提交不批改。（特殊情况，请找班主任请假。）\n",
    "## 3. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**理论部分**  \n",
    "无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编程实践部分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 爬虫数据集筛选及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved in  ./data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Administrator\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce\n",
    "\n",
    "# 以前遇到过的函数\n",
    "\n",
    "def build_url(city_coding, year=None, month=None):\n",
    "    \"\"\"\n",
    "    创建网页链接\n",
    "    paramters:\n",
    "        city_coding: 城市名称(英文)\n",
    "        year: 年份\n",
    "        month: 月份\n",
    "    return:\n",
    "        url: 可访问的链接\n",
    "    \"\"\"\n",
    "    BASE = 'http://www.tianqihoubao.com/aqi/'\n",
    "    city_base_url = BASE + '{}.html'\n",
    "    city_date_base_url = BASE + '{}-{}{}.html'\n",
    "    \n",
    "    if year is not None and month is not None:\n",
    "        month = str(month) if month >= 10 else '0' + str(month)\n",
    "        return city_date_base_url.format(city_coding, year, month)\n",
    "    else:\n",
    "        return city_base_url.format(city_coding)\n",
    "\n",
    "\n",
    "def parse(url, city_name):\n",
    "    \"\"\"\n",
    "    抓取网页信息\n",
    "    parameters:\n",
    "        url: 需要抓取的网页链接\n",
    "        city_name: 城市名称(用于数据标识)\n",
    "    returns:\n",
    "        result: 抓取的信息\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "        \n",
    "        soup = BeautifulSoup(html)\n",
    "        data_table = soup.table\n",
    "        \n",
    "        content = data_table.contents\n",
    "        \n",
    "        result = []\n",
    "        for index, c in enumerate(content[1::2]):\n",
    "                if index == 0:\n",
    "                    result.append(tuple(['城市'] + c.text.split()))\n",
    "                else:\n",
    "                    result.append(tuple([city_name] + c.text.split()))\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        if response.status_code == 403:\n",
    "            print('403 Forbidden! 抓取太快你被拉黑啦~')\n",
    "\n",
    "            \n",
    "def save(data, file):\n",
    "    # 完成数据保存到文件\n",
    "    # your code here\n",
    "    # 提示：用什么方法将数据写入文件？\n",
    "    with open(file,'w') as f:\n",
    "        f.write(data)\n",
    "    print('data saved in ', file)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datas = []\n",
    "    for i in range(1, 2):\n",
    "        url = build_url('hangzhou', 2019, i)\n",
    "        data = parse(url, '杭州')\n",
    "        datas.extend(data)\n",
    "    # print(datas)\n",
    "    \n",
    "    # 只保留质量等级优 良 数据\n",
    "    # your code here\n",
    "    # 提示：用什么方法对数据进行筛选？\n",
    "    \n",
    "    # 保存数据\n",
    "    '''\n",
    "    保存全部数据    \n",
    "    print(datas,type(datas[1]))\n",
    "    st = str(reduce(lambda x,y: x+'\\n'+y,map(str,data)))    \n",
    "    \n",
    "    保存优/良数据\n",
    "    st = str(reduce(lambda x,y: x+'\\n'+y,map(str,filter(lambda x: x[2] == '优' or x[2] == '良',data))))  \n",
    "    '''\n",
    "    st = str(reduce(lambda x,y: x+'\\n'+y,map(str,filter(lambda x: x[2] == '优' or x[2] == '良',data))))  \n",
    "    save(st, './data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 西瓜数据集保存及读取  \n",
    "添加编号列，并将数据集写入到`machine_learning.csv`文件，使用pandas读取验证文件是否有效(无错即可)。  \n",
    "添加一条记录，`青绿 硬挺 浊响 稍糊 平坦 硬滑 0.666 0.111 好`  \n",
    "再使用普通文件读取将数据集读取出来，列名读取到`columns`，数据(带编号)读取到`datalist`  \n",
    "在所有数据中过滤出色泽='浅白'的数据  \n",
    "在所有数据中过滤出密度大于0.5的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************** \n",
      "全部数据\n",
      "         编号,色泽,根蒂,敲声,纹理,脐部,触感,密度,含糖率,好瓜\n",
      "0    1,青绿,蜷缩,浊响,清晰,凹陷,硬滑,0.697,0.460,是\n",
      "1    2,乌黑,蜷缩,沉闷,清晰,凹陷,硬滑,0.774,0.376,是\n",
      "2    3,乌黑,蜷缩,浊响,清晰,凹陷,硬滑,0.634,0.264,是\n",
      "3    4,青绿,蜷缩,沉闷,清晰,凹陷,硬滑,0.608,0.318,是\n",
      "4    5,浅白,蜷缩,浊响,清晰,凹陷,硬滑,0.556,0.215,是\n",
      "5    6,青绿,稍蜷,浊响,清晰,稍凹,软粘,0.403,0.237,是\n",
      "6    7,乌黑,稍蜷,浊响,稍糊,稍凹,软粘,0.481,0.149,是\n",
      "7    8,乌黑,稍蜷,浊响,清晰,稍凹,硬滑,0.437,0.211,是\n",
      "8    9,乌黑,稍蜷,沉闷,稍糊,稍凹,硬滑,0.666,0.091,否\n",
      "9   10,青绿,硬挺,清脆,清晰,平坦,软粘,0.243,0.267,否\n",
      "10  11,浅白,硬挺,清脆,模糊,平坦,硬滑,0.245,0.057,否\n",
      "11  12,浅白,蜷缩,浊响,模糊,平坦,软粘,0.343,0.099,否\n",
      "12  13,青绿,稍蜷,浊响,稍糊,凹陷,硬滑,0.639,0.161,否\n",
      "13  14,浅白,稍蜷,沉闷,稍糊,凹陷,硬滑,0.657,0.198,否\n",
      "14  15,乌黑,稍蜷,浊响,清晰,稍凹,软粘,0.360,0.370,否\n",
      "15  16,浅白,蜷缩,浊响,模糊,平坦,硬滑,0.593,0.042,否\n",
      "16  17,青绿,蜷缩,沉闷,稍糊,稍凹,硬滑,0.719,0.103,否\n",
      "17  18,青绿,硬挺,浊响,稍糊,平坦,硬滑,0.666,0.111,是\n",
      "************************************************** \n",
      "6行数据\n",
      "       编号,色泽,根蒂,敲声,纹理,脐部,触感,密度,含糖率,好瓜\n",
      "0  1,青绿,蜷缩,浊响,清晰,凹陷,硬滑,0.697,0.460,是\n",
      "1  2,乌黑,蜷缩,沉闷,清晰,凹陷,硬滑,0.774,0.376,是\n",
      "2  3,乌黑,蜷缩,浊响,清晰,凹陷,硬滑,0.634,0.264,是\n",
      "3  4,青绿,蜷缩,沉闷,清晰,凹陷,硬滑,0.608,0.318,是\n",
      "4  5,浅白,蜷缩,浊响,清晰,凹陷,硬滑,0.556,0.215,是\n",
      "5  6,青绿,稍蜷,浊响,清晰,稍凹,软粘,0.403,0.237,是\n",
      "True\n",
      "True\n",
      "[['5', '浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '0.556', '0.215', '是'], ['11', '浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', '0.245', '0.057', '否'], ['12', '浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', '0.343', '0.099', '否'], ['14', '浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', '0.657', '0.198', '否'], ['16', '浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', '0.593', '0.042', '否']]\n",
      "[['1', '青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '0.697', '0.460', '是'], ['2', '乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '0.774', '0.376', '是'], ['3', '乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '0.634', '0.264', '是'], ['4', '青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '0.608', '0.318', '是'], ['5', '浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '0.556', '0.215', '是'], ['9', '乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', '0.666', '0.091', '否'], ['13', '青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', '0.639', '0.161', '否'], ['14', '浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', '0.657', '0.198', '否'], ['16', '浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', '0.593', '0.042', '否'], ['17', '青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', '0.719', '0.103', '否'], ['18', '青绿', '硬挺', '浊响', '稍糊', '平坦', '硬滑', '0.666', '0.111', '是']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "dataset = \\\n",
    "\"\"\"色泽 根蒂 敲声 纹理 脐部 触感 密度 含糖率 好瓜\n",
    "青绿 蜷缩 浊响 清晰 凹陷 硬滑 0.697 0.460 是\n",
    "乌黑 蜷缩 沉闷 清晰 凹陷 硬滑 0.774 0.376 是\n",
    "乌黑 蜷缩 浊响 清晰 凹陷 硬滑 0.634 0.264 是\n",
    "青绿 蜷缩 沉闷 清晰 凹陷 硬滑 0.608 0.318 是\n",
    "浅白 蜷缩 浊响 清晰 凹陷 硬滑 0.556 0.215 是\n",
    "青绿 稍蜷 浊响 清晰 稍凹 软粘 0.403 0.237 是\n",
    "乌黑 稍蜷 浊响 稍糊 稍凹 软粘 0.481 0.149 是\n",
    "乌黑 稍蜷 浊响 清晰 稍凹 硬滑 0.437 0.211 是\n",
    "乌黑 稍蜷 沉闷 稍糊 稍凹 硬滑 0.666 0.091 否\n",
    "青绿 硬挺 清脆 清晰 平坦 软粘 0.243 0.267 否\n",
    "浅白 硬挺 清脆 模糊 平坦 硬滑 0.245 0.057 否\n",
    "浅白 蜷缩 浊响 模糊 平坦 软粘 0.343 0.099 否\n",
    "青绿 稍蜷 浊响 稍糊 凹陷 硬滑 0.639 0.161 否\n",
    "浅白 稍蜷 沉闷 稍糊 凹陷 硬滑 0.657 0.198 否\n",
    "乌黑 稍蜷 浊响 清晰 稍凹 软粘 0.360 0.370 否\n",
    "浅白 蜷缩 浊响 模糊 平坦 硬滑 0.593 0.042 否\n",
    "青绿 蜷缩 沉闷 稍糊 稍凹 硬滑 0.719 0.103 否\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "数据处理\n",
    "'''\n",
    "file = r'machine_learning.csv'\n",
    "class Data_p():\n",
    "      \n",
    "    #数据插入\n",
    "    def d_insert(self,path,data):\n",
    "        with open(path,'a') as f:\n",
    "            f.write(data)\n",
    "    \n",
    "    # ' ' 转换成 ，\n",
    "    def str_p(self,s):\n",
    "        st = ','.join(s.split(' '))\n",
    "        return st\n",
    "    \n",
    "    # 数据标序号\n",
    "    def c_number(self,list_s):\n",
    "        list2str = '编号,'+list_s[0]+'\\n'\n",
    "        for s in range(1,len(list_s)):\n",
    "            list2str += str(s)+','+list_s[s]+'\\n'\n",
    "        return list2str\n",
    "        \n",
    "        \n",
    "data_p = Data_p()\n",
    "'''\n",
    "dataset插入CSV\n",
    "'''\n",
    "num_data = data_p.c_number(data_p.str_p(dataset).splitlines())\n",
    "data_p.d_insert(file,num_data)\n",
    "'''\n",
    "插入inser_data数据\n",
    "'''\n",
    "inser_data = '18 青绿 硬挺 浊响 稍糊 平坦 硬滑 0.666 0.111 是'\n",
    "data_p.d_insert(file,data_p.str_p(inser_data))\n",
    "'''\n",
    "读取全部数据\n",
    "'''\n",
    "df = pd.read_csv(file,'gbk')\n",
    "print('*'*50,'\\n全部数据\\n',df)\n",
    "print('*'*50,'\\n6行数据\\n',df.head(6))\n",
    "'''\n",
    "读取文件存储的数据\n",
    " - columns是指列标签\n",
    " - datalist指全体数据内容，每一行数据应为一个列表\n",
    "'''\n",
    "columns = []\n",
    "datalist = []\n",
    "with open(file,'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i in reader:\n",
    "        datalist.append(i)\n",
    "columns = datalist[0]\n",
    "print(columns==['编号', '色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖率', '好瓜'])\n",
    "print(datalist[-1]==['18','青绿', '硬挺', '浊响', '稍糊', '平坦', '硬滑', '0.666', '0.111', '是'])\n",
    "\n",
    "'''\n",
    "在所有数据中过滤出色泽='浅白'的数据\n",
    "'''\n",
    "print(list(filter(lambda x : x[1] == '浅白',datalist)))\n",
    "'''\n",
    "在所有数据中过滤出密度大于0.5的数据\n",
    "'''\n",
    "print(list(filter(lambda x : float(x[7])>0.5, datalist[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 评阅点：\n",
    "1. 使用,替代空格，并添加编号写入csv文件，可通过pandas进行验证  \n",
    "2. 使用a模式进行数据添加\n",
    "3. 读取数据文件并存到对应变量，注意strip，可根据最后验证代码进行验证  \n",
    "4. 使用filter lambda配合进行条件过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
